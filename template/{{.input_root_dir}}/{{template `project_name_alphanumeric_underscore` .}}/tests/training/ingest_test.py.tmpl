import pytest
import pandas as pd
import numpy as np
from pandas import DataFrame


@pytest.fixture
def sample_spark_tables_data():
    """Create sample data that mimics the four Spark tables used in ingestion"""
    np.random.seed(42)
    n_samples = 100
    
    # Create sample data for four tables
    first_df = pd.DataFrame({
        'id': range(n_samples),
        'feature_1': np.random.randn(n_samples),
        'feature_2': np.random.randn(n_samples),
        'target_label': np.random.randint(0, 2, n_samples)
    })
    
    second_df = pd.DataFrame({
        'id': range(n_samples),
        'feature_3': np.random.randn(n_samples),
        'feature_4': np.random.randn(n_samples)
    })
    
    third_df = pd.DataFrame({
        'id': range(n_samples),
        'feature_5': np.random.randn(n_samples),
        'feature_6': np.random.randn(n_samples)
    })
    
    forth_df = pd.DataFrame({
        'id': range(n_samples),
        'feature_7': np.random.randn(n_samples),
        'feature_8': np.random.randn(n_samples)
    })
    
    return first_df, second_df, third_df, forth_df


def test_data_ingestion_structure(sample_spark_tables_data):
    """Test that ingested data has the correct structure after joining"""
    first_df, second_df, third_df, forth_df = sample_spark_tables_data
    
    # Simulate the LEFT JOIN operation from the ingestion script
    result_df = first_df.merge(second_df, on='id', how='left')\
                       .merge(third_df, on='id', how='left')\
                       .merge(forth_df, on='id', how='left')
    
    # Assertions
    assert isinstance(result_df, DataFrame)
    assert not result_df.empty
    assert 'id' in result_df.columns
    assert 'target_label' in result_df.columns
    
    # Check that all features from all tables are present
    expected_features = ['feature_1', 'feature_2', 'feature_3', 'feature_4', 
                       'feature_5', 'feature_6', 'feature_7', 'feature_8']
    for feature in expected_features:
        assert feature in result_df.columns
    
    # Check data quality
    assert result_df['id'].is_unique
    assert not result_df['id'].isna().any()


def test_data_quality_checks(sample_spark_tables_data):
    """Test data quality checks that should be performed during ingestion"""
    first_df, second_df, third_df, forth_df = sample_spark_tables_data
    
    # Simulate joined data
    result_df = first_df.merge(second_df, on='id', how='left')\
                       .merge(third_df, on='id', how='left')\
                       .merge(forth_df, on='id', how='left')
    
    # Test null value checks
    null_counts = result_df.isnull().sum()
    assert isinstance(null_counts, pd.Series)
    
    # Test duplicate check
    duplicate_count = result_df.duplicated().sum()
    assert duplicate_count >= 0
    
    # Test row count
    assert len(result_df) > 0
    assert len(result_df) == len(first_df)  # Should match the base table


def test_target_variable_presence(sample_spark_tables_data):
    """Test that the target variable is properly included in ingested data"""
    first_df, second_df, third_df, forth_df = sample_spark_tables_data
    
    # Simulate joined data
    result_df = first_df.merge(second_df, on='id', how='left')\
                       .merge(third_df, on='id', how='left')\
                       .merge(forth_df, on='id', how='left')
    
    # Check target variable
    assert 'target_label' in result_df.columns
    assert not result_df['target_label'].isna().all()
    
    # Check target variable values are binary
    unique_targets = result_df['target_label'].unique()
    assert all(target in [0, 1] for target in unique_targets)
