# ML Developer Guide

[(back to project README)](../README.md)

## Table of contents
* [Initial setup](#initial-setup): adapting the provided example code to your ML problem
* [Iterating on ML code](#iterating-on-ml-code): making and testing ML code changes on Databricks or your local machine.
* [Next steps](#next-steps)

## Initial setup
This folder contains example ML code to train a regression model to predict NYC taxi fares.

The training pipeline is implemented using standard MLflow tracking and model registration. You can adapt this code to your own ML problem by modifying the training notebook and related components.

## Iterating on ML code

### Deploy ML code and resources to dev workspace using Bundles

Refer to [Local development and dev workspace](../resources/README.md#local-development-and-dev-workspace)
to use databricks CLI bundles to deploy ML code together with ML resource configs to dev workspace. 

### Develop on Databricks using Databricks Repos

#### Prerequisites
You'll need:
* Access to run commands on a cluster running Databricks Runtime ML version 11.0 or above in your dev Databricks workspace
* To set up [Databricks Repos]({{ template `generate_doc_link` (map (pair "cloud" .input_cloud) (pair "path" "repos/index.html")) }}): see instructions below

#### Configuring Databricks Repos
To use Repos, [set up git integration]({{ template `generate_doc_link` (map (pair "cloud" .input_cloud) (pair "path" "repos/repos-setup.html")) }}) in your dev workspace.

If the current project has already been pushed to a hosted Git repo, follow the
[UI workflow]({{ template `generate_doc_link` (map (pair "cloud" .input_cloud) (pair "path" "repos/git-operations-with-repos#add-a-repo-and-connect-remotely-later")) }})
to clone it into your dev workspace and iterate.

Otherwise, e.g. if iterating on ML code for a new project, follow the steps below:
* Follow the [UI workflow]({{ template `generate_doc_link` (map (pair "cloud" .input_cloud) (pair "path" "repos/git-operations-with-repos#add-a-repo-and-connect-remotely-later")) }})
  for creating a repo, but uncheck the "Create repo by cloning a Git repository" checkbox.
* Install the `dbx` CLI via `pip install --upgrade dbx`
* Run `databricks configure --profile {{ .input_project_name }}-dev --token --host <your-dev-workspace-url>`, passing the URL of your dev workspace.
  This should prompt you to enter an API token
* [Create a personal access token]({{ template `generate_doc_link` (map (pair "cloud" .input_cloud) (pair "path" "dev-tools/auth/pat.html")) }})
  in your dev workspace and paste it into the prompt from the previous step
* From within the root directory of the current project, use the [dbx sync](https://dbx.readthedocs.io/en/latest/guides/python/devloop/mixed/#using-dbx-sync-repo-for-local-to-repo-synchronization) tool to copy code files from your local machine into the Repo by running
  `dbx sync repo --profile {{ .input_project_name }}-dev --source . --dest-repo your-repo-name`, where `your-repo-name` should be the last segment of the full repo name (`/Repos/username/your-repo-name`)

#### Running code on Databricks
You can iterate on ML code by running the provided `{{template `project_name_alphanumeric_underscore` .}}/training/notebooks/Train.py` notebook on Databricks using
[Repos]({{ template `generate_doc_link` (map (pair "cloud" .input_cloud) (pair "path" "repos/index.html")) }}). This notebook contains the complete training pipeline and can be modified to adapt to your specific ML problem.

### Develop locally

You can also iterate on ML code locally.

#### Prerequisites
* Python 3.8+
* Install model training and test dependencies via `pip install -I -r {{template `project_name_alphanumeric_underscore` .}}/requirements.txt -r test-requirements.txt` from project root directory.

#### Trigger model training
You can run the training notebook locally or adapt the training logic to run as a Python script. The training notebook demonstrates:
- Loading and preprocessing data
- Training a model using MLflow
- Logging metrics and artifacts
- Registering the model in MLflow Model Registry

#### Inspect results in the UI
To facilitate saving and sharing results from local iteration with collaborators, we recommend configuring your
environment to log to a Databricks MLflow tracking server, as described in [this guide]({{ template `generate_doc_link` (map (pair "cloud" .input_cloud) (pair "path" "mlflow/access-hosted-tracking-server.html")) }}).

If you prefer to log results locally, you can view model training results by running the MLflow UI:
```bash
mlflow ui
```

## Next steps
* [Model validation](../validation/README.md): validate model performance before deployment
* [Model deployment](../deployment/README.md): deploy models to production
* [Batch inference](../deployment/batch_inference/README.md): set up batch inference pipelines
* [Model monitoring](../monitoring/README.md): monitor model performance in production
